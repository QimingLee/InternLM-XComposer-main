[2024-06-23 17:11:59,644] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-23 17:12:00,496] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-06-23 17:12:00,496] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-06-23 17:12:00,496] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
You are using a model of type internlmxcomposer2 to instantiate a model of type internlm. This is not supported for all configurations of models and can yield errors.
Load model from: /home/qmli/models/internlm-xcomposer2-vl-7b
Set max length to 4096
/home/qmli/anaconda3/envs/intern/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of the model checkpoint at openai/clip-vit-large-patch14-336 were not used when initializing CLIPVisionModel: ['text_model.encoder.layers.5.self_attn.q_proj.weight', 'text_model.encoder.layers.3.self_attn.v_proj.weight', 'text_model.encoder.layers.8.mlp.fc1.bias', 'text_model.encoder.layers.4.mlp.fc2.weight', 'text_model.encoder.layers.4.mlp.fc2.bias', 'text_model.encoder.layers.1.self_attn.v_proj.weight', 'text_model.encoder.layers.7.self_attn.v_proj.bias', 'text_model.encoder.layers.10.self_attn.out_proj.weight', 'text_model.encoder.layers.11.self_attn.out_proj.weight', 'text_model.encoder.layers.6.layer_norm2.weight', 'text_projection.weight', 'text_model.encoder.layers.3.layer_norm2.bias', 'text_model.encoder.layers.11.layer_norm2.weight', 'text_model.encoder.layers.11.self_attn.q_proj.bias', 'text_model.encoder.layers.6.mlp.fc2.bias', 'text_model.encoder.layers.8.layer_norm1.weight', 'text_model.encoder.layers.8.self_attn.q_proj.bias', 'text_model.encoder.layers.2.self_attn.k_proj.weight', 'text_model.encoder.layers.6.layer_norm2.bias', 'text_model.encoder.layers.2.self_attn.out_proj.weight', 'text_model.encoder.layers.9.mlp.fc2.weight', 'text_model.encoder.layers.3.self_attn.k_proj.weight', 'text_model.encoder.layers.4.self_attn.k_proj.bias', 'text_model.encoder.layers.7.self_attn.out_proj.bias', 'text_model.encoder.layers.9.self_attn.out_proj.weight', 'text_model.encoder.layers.11.layer_norm1.bias', 'text_model.encoder.layers.7.self_attn.q_proj.bias', 'text_model.encoder.layers.11.self_attn.out_proj.bias', 'text_model.encoder.layers.8.self_attn.v_proj.weight', 'text_model.encoder.layers.1.self_attn.out_proj.bias', 'text_model.encoder.layers.2.layer_norm2.bias', 'text_model.encoder.layers.6.mlp.fc2.weight', 'text_model.encoder.layers.3.self_attn.out_proj.weight', 'text_model.encoder.layers.2.self_attn.out_proj.bias', 'text_model.encoder.layers.0.layer_norm1.weight', 'text_model.encoder.layers.0.self_attn.out_proj.bias', 'text_model.encoder.layers.6.self_attn.out_proj.weight', 'text_model.encoder.layers.2.self_attn.v_proj.weight', 'text_model.encoder.layers.6.layer_norm1.weight', 'text_model.encoder.layers.5.self_attn.out_proj.weight', 'text_model.encoder.layers.11.self_attn.k_proj.bias', 'text_model.encoder.layers.1.layer_norm1.weight', 'text_model.encoder.layers.8.self_attn.q_proj.weight', 'text_model.encoder.layers.11.layer_norm1.weight', 'text_model.encoder.layers.10.self_attn.q_proj.weight', 'text_model.encoder.layers.10.self_attn.k_proj.bias', 'text_model.encoder.layers.4.self_attn.q_proj.weight', 'text_model.encoder.layers.5.mlp.fc2.weight', 'text_model.encoder.layers.3.self_attn.v_proj.bias', 'text_model.encoder.layers.3.self_attn.q_proj.bias', 'text_model.encoder.layers.10.layer_norm2.bias', 'text_model.encoder.layers.7.self_attn.k_proj.weight', 'text_model.encoder.layers.3.layer_norm2.weight', 'text_model.encoder.layers.11.mlp.fc1.bias', 'text_model.encoder.layers.8.self_attn.k_proj.weight', 'text_model.encoder.layers.10.self_attn.v_proj.weight', 'text_model.encoder.layers.4.layer_norm2.bias', 'text_model.encoder.layers.9.self_attn.v_proj.bias', 'text_model.encoder.layers.1.self_attn.out_proj.weight', 'text_model.encoder.layers.8.self_attn.out_proj.bias', 'text_model.encoder.layers.0.self_attn.out_proj.weight', 'text_model.encoder.layers.7.mlp.fc2.bias', 'text_model.encoder.layers.9.layer_norm2.bias', 'text_model.encoder.layers.5.layer_norm2.bias', 'text_model.encoder.layers.0.mlp.fc1.weight', 'text_model.encoder.layers.3.self_attn.out_proj.bias', 'text_model.encoder.layers.1.self_attn.k_proj.bias', 'text_model.encoder.layers.0.self_attn.q_proj.bias', 'text_model.encoder.layers.1.self_attn.v_proj.bias', 'text_model.encoder.layers.4.self_attn.out_proj.bias', 'text_model.encoder.layers.11.self_attn.v_proj.weight', 'text_model.encoder.layers.4.self_attn.q_proj.bias', 'text_model.encoder.layers.9.self_attn.v_proj.weight', 'text_model.encoder.layers.5.self_attn.q_proj.bias', 'text_model.encoder.layers.0.mlp.fc2.weight', 'text_model.encoder.layers.2.layer_norm1.weight', 'text_model.encoder.layers.9.layer_norm1.weight', 'text_model.encoder.layers.6.self_attn.k_proj.weight', 'text_model.encoder.layers.5.mlp.fc1.weight', 'text_model.encoder.layers.7.mlp.fc1.bias', 'text_model.encoder.layers.11.mlp.fc2.bias', 'text_model.encoder.layers.4.mlp.fc1.bias', 'text_model.encoder.layers.5.layer_norm1.bias', 'text_model.encoder.layers.11.self_attn.k_proj.weight', 'text_model.encoder.layers.7.layer_norm1.weight', 'text_model.encoder.layers.3.mlp.fc1.weight', 'text_model.encoder.layers.9.self_attn.k_proj.weight', 'text_model.encoder.layers.3.mlp.fc2.weight', 'text_model.encoder.layers.9.self_attn.q_proj.weight', 'text_model.encoder.layers.11.layer_norm2.bias', 'text_model.encoder.layers.10.mlp.fc1.weight', 'text_model.encoder.layers.8.layer_norm1.bias', 'text_model.encoder.layers.7.layer_norm2.weight', 'text_model.encoder.layers.7.layer_norm2.bias', 'text_model.encoder.layers.9.mlp.fc1.bias', 'text_model.embeddings.token_embedding.weight', 'text_model.encoder.layers.0.self_attn.v_proj.weight', 'text_model.encoder.layers.11.mlp.fc2.weight', 'text_model.encoder.layers.1.layer_norm1.bias', 'text_model.encoder.layers.6.self_attn.k_proj.bias', 'text_model.encoder.layers.9.layer_norm2.weight', 'text_model.final_layer_norm.weight', 'text_model.encoder.layers.2.mlp.fc2.bias', 'text_model.encoder.layers.4.self_attn.k_proj.weight', 'text_model.encoder.layers.0.mlp.fc1.bias', 'text_model.encoder.layers.6.self_attn.q_proj.bias', 'text_model.encoder.layers.3.layer_norm1.bias', 'text_model.encoder.layers.2.mlp.fc1.bias', 'text_model.encoder.layers.2.self_attn.q_proj.bias', 'text_model.encoder.layers.8.mlp.fc1.weight', 'text_model.encoder.layers.11.mlp.fc1.weight', 'text_model.encoder.layers.3.mlp.fc1.bias', 'text_model.encoder.layers.10.self_attn.k_proj.weight', 'text_model.encoder.layers.0.layer_norm2.bias', 'text_model.encoder.layers.8.self_attn.k_proj.bias', 'text_model.encoder.layers.7.self_attn.q_proj.weight', 'text_model.encoder.layers.10.mlp.fc1.bias', 'text_model.encoder.layers.3.self_attn.q_proj.weight', 'text_model.encoder.layers.10.layer_norm2.weight', 'text_model.encoder.layers.6.self_attn.v_proj.bias', 'text_model.encoder.layers.1.mlp.fc1.bias', 'text_model.encoder.layers.7.mlp.fc1.weight', 'text_model.encoder.layers.3.mlp.fc2.bias', 'text_model.encoder.layers.5.self_attn.out_proj.bias', 'text_model.encoder.layers.10.self_attn.q_proj.bias', 'text_model.encoder.layers.8.layer_norm2.weight', 'text_model.encoder.layers.9.mlp.fc2.bias', 'visual_projection.weight', 'text_model.encoder.layers.3.self_attn.k_proj.bias', 'text_model.encoder.layers.1.layer_norm2.bias', 'text_model.encoder.layers.1.mlp.fc2.weight', 'text_model.encoder.layers.0.mlp.fc2.bias', 'logit_scale', 'text_model.encoder.layers.6.self_attn.out_proj.bias', 'text_model.encoder.layers.5.self_attn.k_proj.bias', 'text_model.encoder.layers.5.mlp.fc2.bias', 'text_model.encoder.layers.0.self_attn.k_proj.bias', 'text_model.encoder.layers.2.self_attn.k_proj.bias', 'text_model.encoder.layers.1.mlp.fc1.weight', 'text_model.encoder.layers.6.self_attn.v_proj.weight', 'text_model.encoder.layers.1.self_attn.k_proj.weight', 'text_model.encoder.layers.8.self_attn.out_proj.weight', 'text_model.encoder.layers.9.self_attn.out_proj.bias', 'text_model.encoder.layers.7.self_attn.k_proj.bias', 'text_model.encoder.layers.6.layer_norm1.bias', 'text_model.encoder.layers.10.mlp.fc2.weight', 'text_model.encoder.layers.6.mlp.fc1.bias', 'text_model.encoder.layers.7.self_attn.out_proj.weight', 'text_model.encoder.layers.7.mlp.fc2.weight', 'text_model.encoder.layers.5.layer_norm2.weight', 'text_model.encoder.layers.8.layer_norm2.bias', 'text_model.encoder.layers.0.layer_norm2.weight', 'text_model.encoder.layers.2.self_attn.q_proj.weight', 'text_model.encoder.layers.9.self_attn.k_proj.bias', 'text_model.encoder.layers.2.layer_norm1.bias', 'text_model.encoder.layers.5.self_attn.k_proj.weight', 'text_model.encoder.layers.6.mlp.fc1.weight', 'text_model.encoder.layers.0.layer_norm1.bias', 'text_model.encoder.layers.1.layer_norm2.weight', 'text_model.encoder.layers.2.mlp.fc2.weight', 'text_model.encoder.layers.8.mlp.fc2.bias', 'text_model.encoder.layers.2.mlp.fc1.weight', 'text_model.encoder.layers.10.self_attn.out_proj.bias', 'text_model.encoder.layers.5.self_attn.v_proj.bias', 'text_model.embeddings.position_embedding.weight', 'text_model.encoder.layers.2.layer_norm2.weight', 'text_model.encoder.layers.5.self_attn.v_proj.weight', 'text_model.encoder.layers.3.layer_norm1.weight', 'text_model.final_layer_norm.bias', 'text_model.encoder.layers.0.self_attn.v_proj.bias', 'text_model.encoder.layers.4.layer_norm1.bias', 'text_model.encoder.layers.8.self_attn.v_proj.bias', 'text_model.encoder.layers.4.layer_norm2.weight', 'text_model.encoder.layers.11.self_attn.q_proj.weight', 'text_model.encoder.layers.6.self_attn.q_proj.weight', 'text_model.encoder.layers.4.self_attn.out_proj.weight', 'text_model.encoder.layers.9.layer_norm1.bias', 'text_model.encoder.layers.1.self_attn.q_proj.bias', 'text_model.encoder.layers.2.self_attn.v_proj.bias', 'text_model.encoder.layers.7.layer_norm1.bias', 'text_model.encoder.layers.4.layer_norm1.weight', 'text_model.encoder.layers.11.self_attn.v_proj.bias', 'text_model.encoder.layers.4.self_attn.v_proj.bias', 'text_model.encoder.layers.5.mlp.fc1.bias', 'text_model.encoder.layers.9.mlp.fc1.weight', 'text_model.encoder.layers.10.mlp.fc2.bias', 'text_model.encoder.layers.10.layer_norm1.weight', 'text_model.encoder.layers.1.self_attn.q_proj.weight', 'text_model.encoder.layers.9.self_attn.q_proj.bias', 'text_model.encoder.layers.10.layer_norm1.bias', 'text_model.encoder.layers.8.mlp.fc2.weight', 'text_model.embeddings.position_ids', 'text_model.encoder.layers.7.self_attn.v_proj.weight', 'text_model.encoder.layers.4.self_attn.v_proj.weight', 'text_model.encoder.layers.0.self_attn.k_proj.weight', 'text_model.encoder.layers.5.layer_norm1.weight', 'text_model.encoder.layers.10.self_attn.v_proj.bias', 'text_model.encoder.layers.4.mlp.fc1.weight', 'text_model.encoder.layers.0.self_attn.q_proj.weight', 'text_model.encoder.layers.1.mlp.fc2.bias']
- This IS expected if you are initializing CLIPVisionModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing CLIPVisionModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:21<00:00, 10.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:21<00:00, 10.66s/it]
Some weights of InternLMXComposer2ForCausalLM were not initialized from the model checkpoint at /home/qmli/models/internlm-xcomposer2-vl-7b and are newly initialized: ['vit.vision_tower.vision_model.post_layernorm.bias', 'vit.vision_tower.vision_model.embeddings.position_ids', 'vit.vision_tower.vision_model.post_layernorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
trainable params: 150,994,944 || all params: 8,817,835,008 || trainable%: 1.7123811441585095
Loading data...
Load 39000 samples from ['/home/qmli/InternLM-XComposer-main/data_eccv/train/vqa_anno/train_val_merge_data.json', '39']
init mix data at rank 0
load 39000 data
39000samples is loaded
True
Rank: 0 partition count [1] and sizes[(150994944, False)] 
  0%|          | 0/9750 [00:00<?, ?it/s]Set seed 28664 for rank 0
/home/qmli/anaconda3/envs/intern/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Could not estimate the number of tokens of the input, floating-point operations will not be computed
/home/qmli/anaconda3/envs/intern/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
  0%|          | 1/9750 [00:15<42:51:15, 15.82s/it]                                                   {'loss': 2.4054, 'learning_rate': 5.1020408163265303e-08, 'epoch': 0.0}
  0%|          | 1/9750 [00:15<42:51:15, 15.82s/it]  0%|          | 2/9750 [00:25<33:38:58, 12.43s/it]                                                   {'loss': 2.4917, 'learning_rate': 1.0204081632653061e-07, 'epoch': 0.0}
  0%|          | 2/9750 [00:25<33:38:58, 12.43s/it]  0%|          | 3/9750 [00:35<30:14:21, 11.17s/it]                                                   {'loss': 2.5265, 'learning_rate': 1.5306122448979592e-07, 'epoch': 0.0}
  0%|          | 3/9750 [00:35<30:14:21, 11.17s/it]  0%|          | 4/9750 [00:45<29:19:21, 10.83s/it]                                                   {'loss': 2.1902, 'learning_rate': 2.0408163265306121e-07, 'epoch': 0.0}
  0%|          | 4/9750 [00:45<29:19:21, 10.83s/it]  0%|          | 5/9750 [00:55<28:29:12, 10.52s/it]                                                   {'loss': 2.4421, 'learning_rate': 2.5510204081632656e-07, 'epoch': 0.0}
  0%|          | 5/9750 [00:55<28:29:12, 10.52s/it]  0%|          | 6/9750 [01:05<27:58:58, 10.34s/it]                                                   {'loss': 2.3575, 'learning_rate': 3.0612244897959183e-07, 'epoch': 0.0}
  0%|          | 6/9750 [01:05<27:58:58, 10.34s/it]  0%|          | 7/9750 [01:15<27:16:35, 10.08s/it]                                                   {'loss': 2.3034, 'learning_rate': 3.5714285714285716e-07, 'epoch': 0.0}
  0%|          | 7/9750 [01:15<27:16:35, 10.08s/it]  0%|          | 8/9750 [01:25<27:03:13, 10.00s/it]                                                   {'loss': 2.4201, 'learning_rate': 4.0816326530612243e-07, 'epoch': 0.0}
  0%|          | 8/9750 [01:25<27:03:13, 10.00s/it]  0%|          | 9/9750 [01:35<27:11:22, 10.05s/it]                                                   {'loss': 2.1238, 'learning_rate': 4.591836734693878e-07, 'epoch': 0.0}
  0%|          | 9/9750 [01:35<27:11:22, 10.05s/it]  0%|          | 10/9750 [01:45<27:02:06,  9.99s/it]                                                    {'loss': 2.2583, 'learning_rate': 5.102040816326531e-07, 'epoch': 0.0}
  0%|          | 10/9750 [01:45<27:02:06,  9.99s/it]  0%|          | 11/9750 [01:55<27:15:20, 10.08s/it]                                                    {'loss': 2.0506, 'learning_rate': 5.612244897959184e-07, 'epoch': 0.0}
  0%|          | 11/9750 [01:55<27:15:20, 10.08s/it]  0%|          | 12/9750 [02:05<27:10:13, 10.04s/it]                                                    {'loss': 2.1814, 'learning_rate': 6.122448979591837e-07, 'epoch': 0.0}
  0%|          | 12/9750 [02:05<27:10:13, 10.04s/it]  0%|          | 13/9750 [02:15<27:09:30, 10.04s/it]                                                    {'loss': 2.4026, 'learning_rate': 6.632653061224491e-07, 'epoch': 0.0}
  0%|          | 13/9750 [02:15<27:09:30, 10.04s/it]  0%|          | 14/9750 [02:25<27:23:21, 10.13s/it]                                                    {'loss': 2.2948, 'learning_rate': 7.142857142857143e-07, 'epoch': 0.0}
  0%|          | 14/9750 [02:25<27:23:21, 10.13s/it]  0%|          | 15/9750 [02:35<27:18:37, 10.10s/it]                                                    {'loss': 2.1068, 'learning_rate': 7.653061224489796e-07, 'epoch': 0.0}
  0%|          | 15/9750 [02:35<27:18:37, 10.10s/it]  0%|          | 16/9750 [02:46<27:27:14, 10.15s/it]                                                    {'loss': 2.2423, 'learning_rate': 8.163265306122449e-07, 'epoch': 0.0}
  0%|          | 16/9750 [02:46<27:27:14, 10.15s/it]  0%|          | 17/9750 [02:56<27:21:03, 10.12s/it]                                                    {'loss': 2.2629, 'learning_rate': 8.673469387755103e-07, 'epoch': 0.0}
  0%|          | 17/9750 [02:56<27:21:03, 10.12s/it]  0%|          | 18/9750 [03:06<27:25:54, 10.15s/it]                                                    {'loss': 2.2233, 'learning_rate': 9.183673469387756e-07, 'epoch': 0.0}
  0%|          | 18/9750 [03:06<27:25:54, 10.15s/it]  0%|          | 19/9750 [03:16<27:34:37, 10.20s/it]                                                    {'loss': 2.3609, 'learning_rate': 9.69387755102041e-07, 'epoch': 0.0}
  0%|          | 19/9750 [03:16<27:34:37, 10.20s/it]  0%|          | 20/9750 [03:26<27:15:35, 10.09s/it]                                                    {'loss': 2.4409, 'learning_rate': 1.0204081632653063e-06, 'epoch': 0.0}
  0%|          | 20/9750 [03:26<27:15:35, 10.09s/it]  0%|          | 21/9750 [03:36<27:22:58, 10.13s/it]                                                    {'loss': 2.4064, 'learning_rate': 1.0714285714285714e-06, 'epoch': 0.0}
  0%|          | 21/9750 [03:36<27:22:58, 10.13s/it]  0%|          | 22/9750 [03:46<27:13:34, 10.08s/it]                                                    {'loss': 2.1657, 'learning_rate': 1.122448979591837e-06, 'epoch': 0.0}
  0%|          | 22/9750 [03:46<27:13:34, 10.08s/it]  0%|          | 23/9750 [03:57<27:27:29, 10.16s/it]                                                    {'loss': 2.3126, 'learning_rate': 1.1734693877551022e-06, 'epoch': 0.0}
  0%|          | 23/9750 [03:57<27:27:29, 10.16s/it]  0%|          | 24/9750 [04:07<27:42:59, 10.26s/it]                                                    {'loss': 2.198, 'learning_rate': 1.2244897959183673e-06, 'epoch': 0.0}
  0%|          | 24/9750 [04:07<27:42:59, 10.26s/it]  0%|          | 25/9750 [04:17<27:26:29, 10.16s/it]                                                    {'loss': 2.3848, 'learning_rate': 1.2755102040816329e-06, 'epoch': 0.01}
  0%|          | 25/9750 [04:17<27:26:29, 10.16s/it]  0%|          | 26/9750 [04:27<27:34:35, 10.21s/it]                                                    {'loss': 2.1734, 'learning_rate': 1.3265306122448982e-06, 'epoch': 0.01}
  0%|          | 26/9750 [04:27<27:34:35, 10.21s/it]  0%|          | 27/9750 [04:37<27:17:23, 10.10s/it]                                                    {'loss': 2.3492, 'learning_rate': 1.3775510204081633e-06, 'epoch': 0.01}
  0%|          | 27/9750 [04:37<27:17:23, 10.10s/it]  0%|          | 28/9750 [04:47<27:27:57, 10.17s/it]                                                    {'loss': 1.9896, 'learning_rate': 1.4285714285714286e-06, 'epoch': 0.01}
  0%|          | 28/9750 [04:47<27:27:57, 10.17s/it]  0%|          | 29/9750 [04:58<27:23:50, 10.15s/it]                                                    {'loss': 2.3091, 'learning_rate': 1.479591836734694e-06, 'epoch': 0.01}
  0%|          | 29/9750 [04:58<27:23:50, 10.15s/it]  0%|          | 30/9750 [05:08<27:45:58, 10.28s/it]                                                    {'loss': 2.2784, 'learning_rate': 1.5306122448979593e-06, 'epoch': 0.01}
  0%|          | 30/9750 [05:08<27:45:58, 10.28s/it]  0%|          | 31/9750 [05:18<27:28:56, 10.18s/it]                                                    {'loss': 2.2909, 'learning_rate': 1.5816326530612248e-06, 'epoch': 0.01}
  0%|          | 31/9750 [05:18<27:28:56, 10.18s/it]  0%|          | 32/9750 [05:28<27:19:27, 10.12s/it]                                                    {'loss': 2.2313, 'learning_rate': 1.6326530612244897e-06, 'epoch': 0.01}
  0%|          | 32/9750 [05:28<27:19:27, 10.12s/it]  0%|          | 33/9750 [05:38<27:28:15, 10.18s/it]                                                    {'loss': 2.2705, 'learning_rate': 1.6836734693877552e-06, 'epoch': 0.01}
  0%|          | 33/9750 [05:38<27:28:15, 10.18s/it]  0%|          | 34/9750 [05:49<27:26:05, 10.17s/it]                                                    {'loss': 2.1059, 'learning_rate': 1.7346938775510206e-06, 'epoch': 0.01}
  0%|          | 34/9750 [05:49<27:26:05, 10.17s/it]  0%|          | 35/9750 [05:58<27:10:52, 10.07s/it]                                                    {'loss': 2.3513, 'learning_rate': 1.7857142857142859e-06, 'epoch': 0.01}
  0%|          | 35/9750 [05:58<27:10:52, 10.07s/it]  0%|          | 36/9750 [06:09<27:30:51, 10.20s/it]                                                    {'loss': 2.4927, 'learning_rate': 1.8367346938775512e-06, 'epoch': 0.01}
  0%|          | 36/9750 [06:09<27:30:51, 10.20s/it]  0%|          | 37/9750 [06:19<27:40:08, 10.26s/it]                                                    {'loss': 2.1073, 'learning_rate': 1.8877551020408163e-06, 'epoch': 0.01}
  0%|          | 37/9750 [06:19<27:40:08, 10.26s/it]  0%|          | 38/9750 [06:29<27:11:04, 10.08s/it]                                                    {'loss': 2.3121, 'learning_rate': 1.938775510204082e-06, 'epoch': 0.01}
  0%|          | 38/9750 [06:29<27:11:04, 10.08s/it]  0%|          | 39/9750 [06:39<27:25:23, 10.17s/it]                                                    {'loss': 2.4392, 'learning_rate': 1.989795918367347e-06, 'epoch': 0.01}
  0%|          | 39/9750 [06:39<27:25:23, 10.17s/it]  0%|          | 40/9750 [06:49<27:21:08, 10.14s/it]                                                    {'loss': 2.2561, 'learning_rate': 2.0408163265306125e-06, 'epoch': 0.01}
  0%|          | 40/9750 [06:49<27:21:08, 10.14s/it]  0%|          | 41/9750 [06:59<27:05:48, 10.05s/it]                                                    {'loss': 2.3137, 'learning_rate': 2.0918367346938776e-06, 'epoch': 0.01}
  0%|          | 41/9750 [06:59<27:05:48, 10.05s/it]  0%|          | 42/9750 [07:09<26:57:05,  9.99s/it]                                                    {'loss': 2.2758, 'learning_rate': 2.1428571428571427e-06, 'epoch': 0.01}
  0%|          | 42/9750 [07:09<26:57:05,  9.99s/it]  0%|          | 43/9750 [07:19<26:46:44,  9.93s/it]                                                    {'loss': 2.2577, 'learning_rate': 2.1938775510204083e-06, 'epoch': 0.01}
  0%|          | 43/9750 [07:19<26:46:44,  9.93s/it]  0%|          | 44/9750 [07:29<26:47:34,  9.94s/it]                                                    {'loss': 2.1973, 'learning_rate': 2.244897959183674e-06, 'epoch': 0.01}
  0%|          | 44/9750 [07:29<26:47:34,  9.94s/it]  0%|          | 45/9750 [07:39<27:13:06, 10.10s/it]                                                    {'loss': 2.2298, 'learning_rate': 2.295918367346939e-06, 'epoch': 0.01}
  0%|          | 45/9750 [07:39<27:13:06, 10.10s/it]  0%|          | 46/9750 [07:49<26:59:26, 10.01s/it]                                                    {'loss': 2.5223, 'learning_rate': 2.3469387755102044e-06, 'epoch': 0.01}
  0%|          | 46/9750 [07:49<26:59:26, 10.01s/it]  0%|          | 47/9750 [07:59<26:40:05,  9.89s/it]                                                    {'loss': 2.3624, 'learning_rate': 2.3979591836734696e-06, 'epoch': 0.01}
  0%|          | 47/9750 [07:59<26:40:05,  9.89s/it]  0%|          | 48/9750 [08:09<26:47:48,  9.94s/it]                                                    {'loss': 2.4437, 'learning_rate': 2.4489795918367347e-06, 'epoch': 0.01}
  0%|          | 48/9750 [08:09<26:47:48,  9.94s/it]  1%|          | 49/9750 [08:19<26:47:11,  9.94s/it]                                                    {'loss': 2.3442, 'learning_rate': 2.5e-06, 'epoch': 0.01}
  1%|          | 49/9750 [08:19<26:47:11,  9.94s/it]  1%|          | 50/9750 [08:29<27:14:39, 10.11s/it]                                                    {'loss': 2.11, 'learning_rate': 2.5510204081632657e-06, 'epoch': 0.01}
  1%|          | 50/9750 [08:29<27:14:39, 10.11s/it]  1%|          | 51/9750 [08:39<27:16:24, 10.12s/it]                                                    {'loss': 2.0596, 'learning_rate': 2.602040816326531e-06, 'epoch': 0.01}
  1%|          | 51/9750 [08:39<27:16:24, 10.12s/it]  1%|          | 52/9750 [08:50<27:43:35, 10.29s/it]                                                    {'loss': 2.0606, 'learning_rate': 2.6530612244897964e-06, 'epoch': 0.01}
  1%|          | 52/9750 [08:50<27:43:35, 10.29s/it]  1%|          | 53/9750 [09:00<27:36:25, 10.25s/it]                                                    {'loss': 2.4478, 'learning_rate': 2.7040816326530615e-06, 'epoch': 0.01}
  1%|          | 53/9750 [09:00<27:36:25, 10.25s/it]  1%|          | 54/9750 [09:11<27:37:46, 10.26s/it]                                                    {'loss': 2.3739, 'learning_rate': 2.7551020408163266e-06, 'epoch': 0.01}
  1%|          | 54/9750 [09:11<27:37:46, 10.26s/it]  1%|          | 55/9750 [09:21<28:11:14, 10.47s/it]                                                    {'loss': 2.2902, 'learning_rate': 2.8061224489795917e-06, 'epoch': 0.01}
  1%|          | 55/9750 [09:21<28:11:14, 10.47s/it]  1%|          | 56/9750 [09:32<28:02:05, 10.41s/it]                                                    {'loss': 2.1768, 'learning_rate': 2.8571428571428573e-06, 'epoch': 0.01}
  1%|          | 56/9750 [09:32<28:02:05, 10.41s/it]  1%|          | 57/9750 [09:42<27:35:30, 10.25s/it]                                                    {'loss': 2.3253, 'learning_rate': 2.908163265306123e-06, 'epoch': 0.01}
  1%|          | 57/9750 [09:42<27:35:30, 10.25s/it]  1%|          | 58/9750 [09:52<27:36:18, 10.25s/it]                                                    {'loss': 2.148, 'learning_rate': 2.959183673469388e-06, 'epoch': 0.01}
  1%|          | 58/9750 [09:52<27:36:18, 10.25s/it]  1%|          | 59/9750 [10:02<27:17:34, 10.14s/it]                                                    {'loss': 2.1199, 'learning_rate': 3.0102040816326534e-06, 'epoch': 0.01}
  1%|          | 59/9750 [10:02<27:17:34, 10.14s/it]  1%|          | 60/9750 [10:12<27:07:45, 10.08s/it]                                                    {'loss': 2.0614, 'learning_rate': 3.0612244897959185e-06, 'epoch': 0.01}
  1%|          | 60/9750 [10:12<27:07:45, 10.08s/it]  1%|          | 61/9750 [10:21<26:48:34,  9.96s/it]                                                    {'loss': 2.3152, 'learning_rate': 3.112244897959184e-06, 'epoch': 0.01}
  1%|          | 61/9750 [10:21<26:48:34,  9.96s/it]  1%|          | 62/9750 [10:32<27:28:06, 10.21s/it]                                                    {'loss': 2.0364, 'learning_rate': 3.1632653061224496e-06, 'epoch': 0.01}
  1%|          | 62/9750 [10:32<27:28:06, 10.21s/it]  1%|          | 63/9750 [10:42<27:25:09, 10.19s/it]                                                    {'loss': 2.0097, 'learning_rate': 3.2142857142857147e-06, 'epoch': 0.01}
  1%|          | 63/9750 [10:42<27:25:09, 10.19s/it]  1%|          | 64/9750 [10:52<27:24:47, 10.19s/it]                                                    {'loss': 2.2499, 'learning_rate': 3.2653061224489794e-06, 'epoch': 0.01}
  1%|          | 64/9750 [10:52<27:24:47, 10.19s/it]  1%|          | 65/9750 [11:02<27:07:37, 10.08s/it]                                                    {'loss': 2.2722, 'learning_rate': 3.316326530612245e-06, 'epoch': 0.01}
  1%|          | 65/9750 [11:02<27:07:37, 10.08s/it]  1%|          | 66/9750 [11:12<26:51:40,  9.99s/it]                                                    {'loss': 2.164, 'learning_rate': 3.3673469387755105e-06, 'epoch': 0.01}
  1%|          | 66/9750 [11:12<26:51:40,  9.99s/it]  1%|          | 67/9750 [11:22<26:41:12,  9.92s/it]                                                    {'loss': 2.0808, 'learning_rate': 3.4183673469387756e-06, 'epoch': 0.01}
  1%|          | 67/9750 [11:22<26:41:12,  9.92s/it]  1%|          | 68/9750 [11:32<26:50:18,  9.98s/it]                                                    {'loss': 2.0731, 'learning_rate': 3.469387755102041e-06, 'epoch': 0.01}
  1%|          | 68/9750 [11:32<26:50:18,  9.98s/it]  1%|          | 69/9750 [11:42<26:35:45,  9.89s/it]                                                    {'loss': 2.303, 'learning_rate': 3.5204081632653062e-06, 'epoch': 0.01}
  1%|          | 69/9750 [11:42<26:35:45,  9.89s/it]  1%|          | 70/9750 [11:53<27:25:00, 10.20s/it]                                                    {'loss': 1.9969, 'learning_rate': 3.5714285714285718e-06, 'epoch': 0.01}
  1%|          | 70/9750 [11:53<27:25:00, 10.20s/it]  1%|          | 71/9750 [12:02<26:59:59, 10.04s/it]                                                    {'loss': 2.2443, 'learning_rate': 3.6224489795918373e-06, 'epoch': 0.01}
  1%|          | 71/9750 [12:02<26:59:59, 10.04s/it]  1%|          | 72/9750 [12:12<27:09:01, 10.10s/it]                                                    {'loss': 2.0686, 'learning_rate': 3.6734693877551024e-06, 'epoch': 0.01}
  1%|          | 72/9750 [12:12<27:09:01, 10.10s/it]  1%|          | 73/9750 [12:22<27:03:14, 10.06s/it]                                                    {'loss': 2.1854, 'learning_rate': 3.724489795918368e-06, 'epoch': 0.01}
  1%|          | 73/9750 [12:22<27:03:14, 10.06s/it]  1%|          | 74/9750 [12:32<26:49:44,  9.98s/it]                                                    {'loss': 2.2006, 'learning_rate': 3.7755102040816327e-06, 'epoch': 0.02}
  1%|          | 74/9750 [12:32<26:49:44,  9.98s/it]  1%|          | 75/9750 [12:43<27:08:27, 10.10s/it]                                                    {'loss': 2.1358, 'learning_rate': 3.826530612244898e-06, 'epoch': 0.02}
  1%|          | 75/9750 [12:43<27:08:27, 10.10s/it]  1%|          | 76/9750 [12:53<27:03:10, 10.07s/it]                                                    {'loss': 1.9673, 'learning_rate': 3.877551020408164e-06, 'epoch': 0.02}
  1%|          | 76/9750 [12:53<27:03:10, 10.07s/it]  1%|          | 77/9750 [13:02<26:50:08,  9.99s/it]                                                    {'loss': 2.1106, 'learning_rate': 3.928571428571429e-06, 'epoch': 0.02}
  1%|          | 77/9750 [13:02<26:50:08,  9.99s/it]  1%|          | 78/9750 [13:13<27:11:43, 10.12s/it]                                                    {'loss': 2.0987, 'learning_rate': 3.979591836734694e-06, 'epoch': 0.02}
  1%|          | 78/9750 [13:13<27:11:43, 10.12s/it]  1%|          | 79/9750 [13:23<27:06:53, 10.09s/it]                                                    {'loss': 2.0164, 'learning_rate': 4.03061224489796e-06, 'epoch': 0.02}
  1%|          | 79/9750 [13:23<27:06:53, 10.09s/it]  1%|          | 80/9750 [13:34<27:34:49, 10.27s/it]                                                    {'loss': 2.0856, 'learning_rate': 4.081632653061225e-06, 'epoch': 0.02}
  1%|          | 80/9750 [13:34<27:34:49, 10.27s/it]  1%|          | 81/9750 [13:44<27:20:10, 10.18s/it]                                                    {'loss': 2.1749, 'learning_rate': 4.13265306122449e-06, 'epoch': 0.02}
  1%|          | 81/9750 [13:44<27:20:10, 10.18s/it]  1%|          | 82/9750 [13:54<27:12:02, 10.13s/it]                                                    {'loss': 2.0699, 'learning_rate': 4.183673469387755e-06, 'epoch': 0.02}
  1%|          | 82/9750 [13:54<27:12:02, 10.13s/it]  1%|          | 83/9750 [14:03<26:58:21, 10.04s/it]                                                    {'loss': 2.0803, 'learning_rate': 4.234693877551021e-06, 'epoch': 0.02}
  1%|          | 83/9750 [14:03<26:58:21, 10.04s/it]  1%|          | 84/9750 [14:14<27:04:59, 10.09s/it]                                                    {'loss': 1.8932, 'learning_rate': 4.2857142857142855e-06, 'epoch': 0.02}
  1%|          | 84/9750 [14:14<27:04:59, 10.09s/it]  1%|          | 85/9750 [14:24<27:20:28, 10.18s/it]                                                    {'loss': 2.0608, 'learning_rate': 4.336734693877551e-06, 'epoch': 0.02}
  1%|          | 85/9750 [14:24<27:20:28, 10.18s/it]  1%|          | 86/9750 [14:34<27:02:57, 10.08s/it]                                                    {'loss': 1.9773, 'learning_rate': 4.3877551020408165e-06, 'epoch': 0.02}
  1%|          | 86/9750 [14:34<27:02:57, 10.08s/it]  1%|          | 87/9750 [14:44<26:50:09, 10.00s/it]                                                    {'loss': 2.1028, 'learning_rate': 4.438775510204082e-06, 'epoch': 0.02}
  1%|          | 87/9750 [14:44<26:50:09, 10.00s/it]  1%|          | 88/9750 [14:54<26:44:41,  9.96s/it]                                                    {'loss': 2.0304, 'learning_rate': 4.489795918367348e-06, 'epoch': 0.02}
  1%|          | 88/9750 [14:54<26:44:41,  9.96s/it]  1%|          | 89/9750 [15:03<26:35:04,  9.91s/it]                                                    {'loss': 1.9081, 'learning_rate': 4.540816326530613e-06, 'epoch': 0.02}
  1%|          | 89/9750 [15:03<26:35:04,  9.91s/it]  1%|          | 90/9750 [15:13<26:29:20,  9.87s/it]                                                    {'loss': 2.0184, 'learning_rate': 4.591836734693878e-06, 'epoch': 0.02}
  1%|          | 90/9750 [15:13<26:29:20,  9.87s/it]  1%|          | 91/9750 [15:23<26:53:15, 10.02s/it]                                                    {'loss': 2.0579, 'learning_rate': 4.642857142857144e-06, 'epoch': 0.02}
  1%|          | 91/9750 [15:23<26:53:15, 10.02s/it]  1%|          | 92/9750 [15:34<27:15:13, 10.16s/it]                                                    {'loss': 2.0519, 'learning_rate': 4.693877551020409e-06, 'epoch': 0.02}
  1%|          | 92/9750 [15:34<27:15:13, 10.16s/it]  1%|          | 93/9750 [15:44<27:07:52, 10.11s/it]                                                    {'loss': 1.9452, 'learning_rate': 4.744897959183674e-06, 'epoch': 0.02}
  1%|          | 93/9750 [15:44<27:07:52, 10.11s/it]  1%|          | 94/9750 [15:54<27:13:45, 10.15s/it]                                                    {'loss': 1.8959, 'learning_rate': 4.795918367346939e-06, 'epoch': 0.02}
  1%|          | 94/9750 [15:54<27:13:45, 10.15s/it]  1%|          | 95/9750 [16:04<26:54:09, 10.03s/it]                                                    {'loss': 1.8312, 'learning_rate': 4.846938775510204e-06, 'epoch': 0.02}
  1%|          | 95/9750 [16:04<26:54:09, 10.03s/it]  1%|          | 96/9750 [16:14<26:41:25,  9.95s/it]                                                    {'loss': 1.988, 'learning_rate': 4.897959183673469e-06, 'epoch': 0.02}
  1%|          | 96/9750 [16:14<26:41:25,  9.95s/it]  1%|          | 97/9750 [16:24<27:07:46, 10.12s/it]                                                    {'loss': 1.8875, 'learning_rate': 4.948979591836735e-06, 'epoch': 0.02}
  1%|          | 97/9750 [16:24<27:07:46, 10.12s/it]  1%|          | 98/9750 [16:34<26:41:58,  9.96s/it]                                                    {'loss': 1.909, 'learning_rate': 5e-06, 'epoch': 0.02}
  1%|          | 98/9750 [16:34<26:41:58,  9.96s/it]  1%|          | 99/9750 [16:44<27:06:57, 10.11s/it]                                                    {'loss': 1.9347, 'learning_rate': 4.999999867573431e-06, 'epoch': 0.02}
  1%|          | 99/9750 [16:44<27:06:57, 10.11s/it]  1%|          | 100/9750 [16:55<27:36:01, 10.30s/it]                                                     {'loss': 1.8563, 'learning_rate': 4.999999470293737e-06, 'epoch': 0.02}
  1%|          | 100/9750 [16:55<27:36:01, 10.30s/it]  1%|          | 101/9750 [17:05<27:39:00, 10.32s/it]                                                     {'loss': 1.8807, 'learning_rate': 4.999998808160961e-06, 'epoch': 0.02}
  1%|          | 101/9750 [17:05<27:39:00, 10.32s/it]  1%|          | 102/9750 [17:15<27:13:27, 10.16s/it]                                                     {'loss': 1.9181, 'learning_rate': 4.999997881175173e-06, 'epoch': 0.02}
  1%|          | 102/9750 [17:15<27:13:27, 10.16s/it]  1%|          | 103/9750 [17:25<26:49:21, 10.01s/it]                                                     {'loss': 1.9546, 'learning_rate': 4.99999668933647e-06, 'epoch': 0.02}
  1%|          | 103/9750 [17:25<26:49:21, 10.01s/it]  1%|          | 104/9750 [17:35<27:03:47, 10.10s/it]                                                     {'loss': 1.9138, 'learning_rate': 4.99999523264498e-06, 'epoch': 0.02}
  1%|          | 104/9750 [17:35<27:03:47, 10.10s/it]  1%|          | 105/9750 [17:45<26:41:42,  9.96s/it]                                                     {'loss': 1.9821, 'learning_rate': 4.999993511100856e-06, 'epoch': 0.02}
  1%|          | 105/9750 [17:45<26:41:42,  9.96s/it]  1%|          | 106/9750 [17:54<26:31:04,  9.90s/it]                                                     {'loss': 1.7631, 'learning_rate': 4.9999915247042805e-06, 'epoch': 0.02}
  1%|          | 106/9750 [17:54<26:31:04,  9.90s/it]  1%|          | 107/9750 [18:04<26:32:34,  9.91s/it]                                                     {'loss': 1.8435, 'learning_rate': 4.999989273455465e-06, 'epoch': 0.02}
  1%|          | 107/9750 [18:04<26:32:34,  9.91s/it]  1%|          | 108/9750 [18:14<26:32:14,  9.91s/it]                                                     {'loss': 1.925, 'learning_rate': 4.999986757354647e-06, 'epoch': 0.02}
  1%|          | 108/9750 [18:14<26:32:14,  9.91s/it]  1%|          | 109/9750 [18:24<26:43:58,  9.98s/it]                                                     {'loss': 2.0003, 'learning_rate': 4.999983976402094e-06, 'epoch': 0.02}
  1%|          | 109/9750 [18:24<26:43:58,  9.98s/it]  1%|          | 110/9750 [18:34<26:32:38,  9.91s/it]                                                     {'loss': 1.8602, 'learning_rate': 4.9999809305981e-06, 'epoch': 0.02}
  1%|          | 110/9750 [18:34<26:32:38,  9.91s/it]  1%|          | 111/9750 [18:44<26:26:37,  9.88s/it]                                                     {'loss': 1.8001, 'learning_rate': 4.999977619942986e-06, 'epoch': 0.02}
  1%|          | 111/9750 [18:44<26:26:37,  9.88s/it]  1%|          | 112/9750 [18:54<26:25:31,  9.87s/it]                                                     {'loss': 1.8997, 'learning_rate': 4.999974044437106e-06, 'epoch': 0.02}
  1%|          | 112/9750 [18:54<26:25:31,  9.87s/it]  1%|          | 113/9750 [19:04<26:17:26,  9.82s/it]                                                     {'loss': 1.9428, 'learning_rate': 4.999970204080837e-06, 'epoch': 0.02}
  1%|          | 113/9750 [19:04<26:17:26,  9.82s/it]  1%|          | 114/9750 [19:14<26:22:59,  9.86s/it]                                                     {'loss': 1.8402, 'learning_rate': 4.999966098874587e-06, 'epoch': 0.02}
  1%|          | 114/9750 [19:14<26:22:59,  9.86s/it]  1%|          | 115/9750 [19:23<26:10:38,  9.78s/it]                                                     {'loss': 1.8349, 'learning_rate': 4.999961728818788e-06, 'epoch': 0.02}
  1%|          | 115/9750 [19:23<26:10:38,  9.78s/it]  1%|          | 116/9750 [19:33<26:14:02,  9.80s/it]                                                     {'loss': 1.9483, 'learning_rate': 4.999957093913907e-06, 'epoch': 0.02}
  1%|          | 116/9750 [19:33<26:14:02,  9.80s/it]  1%|          | 117/9750 [19:43<26:06:52,  9.76s/it]                                                     {'loss': 1.6173, 'learning_rate': 4.999952194160431e-06, 'epoch': 0.02}
  1%|          | 117/9750 [19:43<26:06:52,  9.76s/it]  1%|          | 118/9750 [19:53<26:23:20,  9.86s/it]                                                     {'loss': 1.8723, 'learning_rate': 4.999947029558883e-06, 'epoch': 0.02}
  1%|          | 118/9750 [19:53<26:23:20,  9.86s/it]  1%|          | 119/9750 [20:03<26:50:15, 10.03s/it]                                                     {'loss': 1.9062, 'learning_rate': 4.999941600109806e-06, 'epoch': 0.02}
  1%|          | 119/9750 [20:03<26:50:15, 10.03s/it]  1%|          | 120/9750 [20:14<27:13:40, 10.18s/it]                                                     {'loss': 1.7756, 'learning_rate': 4.99993590581378e-06, 'epoch': 0.02}
  1%|          | 120/9750 [20:14<27:13:40, 10.18s/it]  1%|          | 121/9750 [20:24<27:18:56, 10.21s/it]                                                     {'loss': 1.7271, 'learning_rate': 4.999929946671403e-06, 'epoch': 0.02}
  1%|          | 121/9750 [20:24<27:18:56, 10.21s/it]  1%|▏         | 122/9750 [20:34<26:57:10, 10.08s/it]                                                     {'loss': 1.809, 'learning_rate': 4.9999237226833104e-06, 'epoch': 0.03}
  1%|▏         | 122/9750 [20:34<26:57:10, 10.08s/it]